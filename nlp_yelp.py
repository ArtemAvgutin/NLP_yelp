# -*- coding: utf-8 -*-
"""NLP_yelp

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PUGicODjLfbL1ANDBOBLBz0wwh43IOQx

## Определение тональности текстов отзывов на сайте YELP
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Embedding, GRU, LSTM
from tensorflow.keras import utils
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.callbacks import ModelCheckpoint
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline

num_words = 10000
max_review_len = 100

"""## Загрузка набора данных"""

!wget https://www.dropbox.com/s/ufbhk3kadtnn6h0/yelp_review_polarity_csv.tgz?dl=1 -O yelp_review_polarity_csv.tgz

!tar -xvf yelp_review_polarity_csv.tgz

"""## Просматриваем данные"""

!cat yelp_review_polarity_csv/readme.txt

!head yelp_review_polarity_csv/train.csv

!head yelp_review_polarity_csv/test.csv

!wc -l yelp_review_polarity_csv/train.csv #строк для обучения
!wc -l yelp_review_polarity_csv/test.csv #строк в тестовой части

"""## Загружаем данные в память

Читаем данные из файла
"""

train = pd.read_csv('yelp_review_polarity_csv/train.csv',
                    header=None,
                    names=['Class', 'Review'])

train

"""Выделяем данные для обучения"""

reviews = train['Review']

reviews[:10]

"""Выделяем правильные ответы"""

y_train = train['Class'] - 1

y_train

"""## Токенизация текста"""

reviews[:10]

"""Создаем токенизатор Keras"""

tokenizer = Tokenizer(num_words=num_words)

"""Обучаем токенизатор на отзывах Yelp"""

tokenizer.fit_on_texts(reviews)

"""Просматриваем словарь токенизатора"""

tokenizer.word_index

"""Преобразуем отзывы Yelp в числовое представление"""

sequences = tokenizer.texts_to_sequences(reviews)

"""Просматриваем отзывы в числовом представлении"""

index = 0
print(reviews[index])
print(sequences[index])

tokenizer.word_index['frustration']

"""Ограничиваем длину отзывов"""

x_train = pad_sequences(sequences, maxlen=max_review_len)

x_train[:5]

"""## Создаем нейронную сеть"""

model = Sequential()
model.add(Embedding(num_words, 64, input_length=max_review_len))
model.add(LSTM(128))
model.add(Dense(1, activation='sigmoid'))

model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

"""## Обучаем нейронную сеть

Создаем callback для сохранения нейронной сети на каждой эпохе, если качество работы на проверочном наборе данных улучшилось. Сеть сохраняется в файл `best_model.h5`
"""

model_save_path = 'best_model.h5'
checkpoint_callback = ModelCheckpoint(model_save_path,
                                      monitor='val_accuracy',
                                      save_best_only=True,
                                      verbose=1)

history = model.fit(x_train,
                    y_train,
                    epochs=5,
                    batch_size=128,
                    validation_split=0.1,
                    callbacks=[checkpoint_callback])

plt.plot(history.history['accuracy'],
         label='Доля верных ответов на обучающем наборе')
plt.plot(history.history['val_accuracy'],
         label='Доля верных ответов на проверочном наборе')
plt.xlabel('Эпоха обучения')
plt.ylabel('Доля верных ответов')
plt.legend()
plt.show()

"""Загружаем модель с лучшей долей правильных ответов на проверочном наборе данных"""

model.load_weights(model_save_path)

"""## Загружаем набор данных для тестирования"""

test = pd.read_csv('yelp_review_polarity_csv/test.csv',
                    header=None,
                    names=['Class', 'Review'])

test

"""Преобразуем отзывы в числовое представление

Обратите внимание, что нужно использовать токенизатор, обученный на наборе данных train.
"""

test_sequences = tokenizer.texts_to_sequences(test['Review'])

x_test = pad_sequences(test_sequences, maxlen=max_review_len)

x_test[:10]

"""Правильные ответы"""

y_test = test['Class'] - 1

y_test

"""## Оцениваем качество работы сети на тестовом наборе данных"""

model.evaluate(x_test, y_test, verbose=1)

"""## Оцениваем тональность на собственном отзыве"""

text = '''Macdonalds restaurant is worst. It’s a durty place.
The food awful and disgusting.  The host and waiters are rude.
'''

sequence = tokenizer.texts_to_sequences([text])

sequence

data = pad_sequences(sequence, maxlen=max_review_len)

data

result = model.predict(data)

result

if result[[0]] < 0.5:
    print('Negative review')
else:
    print('Positive review')

"""## Определение тональности одномерной сверточной нейросетью"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Embedding, MaxPooling1D, Conv1D, GlobalMaxPooling1D, Dropout

model = Sequential()
model.add(Embedding(num_words, 64, input_length=max_review_len))
model.add(Conv1D(250, 5, padding='valid', activation='relu'))
model.add(GlobalMaxPooling1D())
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(1, activation='sigmoid'))

model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

model.summary()

history = model.fit(x_train,
                    y_train,
                    epochs=5,
                    batch_size=128,
                    validation_split=0.1)

plt.plot(history.history['accuracy'],
         label='Доля верных ответов на обучающем наборе')
plt.plot(history.history['val_accuracy'],
         label='Доля верных ответов на проверочном наборе')
plt.xlabel('Эпоха обучения')
plt.ylabel('Доля верных ответов')
plt.legend()
plt.show()

test = pd.read_csv('yelp_review_polarity_csv/test.csv',
                    header=None,
                    names=['Class', 'Review'])
test

test_sequences = tokenizer.texts_to_sequences(test['Review'])
x_test = pad_sequences(test_sequences, maxlen=max_review_len)
x_test[:9]

y_test = test['Class'] - 1
y_test

"""## Оцениваем тональность на собственном отзыве"""

model.evaluate(x_test, y_test, verbose=1)

text = '''
Everything was delicious. The workers are kind and can always give advice.
'''

sequence = tokenizer.texts_to_sequences([text])
sequence

data = pad_sequences(sequence, maxlen=max_review_len)
data

result = model.predict(data)
result

if result < 0.5:
    print('Отзыв отрицательный')
else:
    print('Отзыв положительный')